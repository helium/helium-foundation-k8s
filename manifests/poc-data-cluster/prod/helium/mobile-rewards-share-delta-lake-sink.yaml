apiVersion: batch/v1
kind: CronJob
metadata:
  name: mobile-rewards-share-delta-lake-sink
  namespace: helium
spec:
  concurrencyPolicy: Forbid
  # Rewards run at 12:30-1am, run this after 
  schedule: "0 2 * * *"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 10
      template:
        spec:
          serviceAccountName: s3-data-lake-bucket-access
          tolerations: # Schedule executor pods on spot-helium instance group
            - key: dedicated
              operator: Equal
              value: spot-helium
              effect: NoSchedule
          nodeSelector:
            nodegroup-type: spot-helium
          containers:
          - name: mobile-rewards-delta-lake-sink
            image: public.ecr.aws/k0m1p4t7/protobuf-delta-lake-sink:0.0.10
            imagePullPolicy: IfNotPresent
            resources:
              requests:
                cpu: 1000m
                memory: 4000Mi
              limits:
                memory: 4000Mi
            env: 
              - name: AWS_S3_ALLOW_UNSAFE_RENAME
                value: "true"
            args:
              - --source-bucket
              - foundation-poc-data-requester-pays
              - --source-region
              - us-west-2
              - --file-prefix
              - foundation-mobile-verified/mobile_reward_share
              - --source-proto-name
              - "mobile_reward_share"
              - --source-proto-base-url
              - https://raw.githubusercontent.com/helium/proto/master/src
              - --source-protos
              - mapper.proto
              - --source-protos
              - service/poc_mobile.proto
              - --target-bucket
              - foundation-data-lake-requester-pays
              - --target-table
              - bronze/mobile_reward_share
              - --target-region
              - us-west-2
              - --partition-timestamp-column
              - start_period
              - --partition-timestamp-date-divisor
              - "86400"
              - --batch-size
              - "500000000" # Targetting 500mb parquet files, per databricks recs on large tables
          restartPolicy: OnFailure